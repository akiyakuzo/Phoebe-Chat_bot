# ==== PATCH PYTHON 3.11 ====
import sys, types
# V√° l·ªói audioop tr√™n m√¥i tr∆∞·ªùng Render/Linux, th∆∞·ªùng g·∫∑p khi d√πng discord.py
sys.modules['audioop'] = types.ModuleType('audioop')

# ========== IMPORTS ==========
import os
import json
import random
import asyncio
import discord
from discord import app_commands
from discord.ext import commands, tasks
from flask import Flask
from threading import Thread
from datetime import datetime
import google.generativeai as genai

# ========== CONFIG GOOGLE GENERATIVE AI (Gemini 2.0 Flash) ==========
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise RuntimeError("‚ö†Ô∏è Thi·∫øu GEMINI_API_KEY!")

# Kh·ªüi t·∫°o Client: ƒê√¢y l√† c√°ch chu·∫©n cho SDK 0.8.0. C·∫ßn ph·∫£i c·ªë g·∫Øng kh·ªüi t·∫°o th√†nh c√¥ng.
try:
    # 1. Kh·ªüi t·∫°o Client: C√°ch chu·∫©n cho SDK 0.8.0+
    client = genai.Client(api_key=GEMINI_API_KEY)
except AttributeError as e:
    # 2. X·ª≠ l√Ω l·ªói n·∫øu genai.Client kh√¥ng t·ªìn t·∫°i (l·ªói m√¥i tr∆∞·ªùng/cache)
    print("üö® L·ªñI NGHI√äM TR·ªåNG: genai.Client kh√¥ng t·ªìn t·∫°i. ƒê√£ c√†i 0.8.0 ch∆∞a?")
    raise RuntimeError(f"L·ªói kh·ªüi t·∫°o Gemini Client: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i qu√° tr√¨nh c√†i ƒë·∫∑t SDK (S·ª≠ d·ª•ng --no-cache-dir)")

MODEL_NAME = "gemini-2.0-flash" 

# ========== CONFIG BOT ==========
BOT_NAME = "Fibi B√©ll üíñ"
TOKEN = os.getenv("TOKEN")
GUILD_ID = int(os.getenv("DISCORD_GUILD_ID", 0))
HISTORY_LIMIT = 20
SESSIONS_FILE = "sessions.json"
flirt_enable = False
active_chats = {}
TYPING_SPEED = 0.02 # ƒê·ªô tr·ªÖ (gi√¢y) gi·ªØa m·ªói k√Ω t·ª±

# ... (PHOBE_SAFE_INSTRUCTION, PROMPTS, DISCORD CONFIG, SESSION SYSTEM gi·ªØ nguy√™n) ...

# PHOBE_SAFE_INSTRUCTION, PHOBE_FLIRT_INSTRUCTION, PHOBE_COMFORT_INSTRUCTION
# PHOBE_BASE_PROMPT, PHOBE_LORE_PROMPT
# DISCORD CONFIG
# SESSION SYSTEM
# ... (Gi·ªØ nguy√™n t·ª´ code tr∆∞·ªõc ƒë√≥) ...

# ========== ASK GEMINI STREAM (S·ª≠ d·ª•ng ƒë·ªëi t∆∞·ª£ng Client) ==========
async def ask_gemini_stream(user_id: str, user_input: str):
    session = get_or_create_chat(user_id)
    history = session["history"]

    user_input = user_input.strip()
    if not user_input:
        yield "‚ö†Ô∏è Kh√¥ng nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi, anh th·ª≠ l·∫°i nh√©!"
        return

    user_input_cleaned = user_input.encode("utf-8", errors="ignore").decode()
    if not user_input_cleaned:
        yield "‚ö†Ô∏è N·ªôi dung c√≥ k√Ω t·ª± l·∫°, em kh√¥ng ƒë·ªçc ƒë∆∞·ª£c. Anh vi·∫øt l·∫°i ƒë∆°n gi·∫£n h∆°n nh√©!"
        return

    if len(history) > HISTORY_LIMIT + 2:
        print(f"‚ö†Ô∏è Reset history user {user_id}")
        last_message = user_input_cleaned
        session["history"] = history[:2] 
        history = session["history"]
        user_input_to_use = last_message
    else:
        user_input_to_use = user_input_cleaned

    lower_input = user_input_to_use.lower()
    if any(w in lower_input for w in ["bu·ªìn", "m·ªát", "ch√°n", "stress", "t·ªá qu√°"]):
        instruction = PHOBE_COMFORT_INSTRUCTION
    elif flirt_enable:
        instruction = PHOBE_FLIRT_INSTRUCTION
    else:
        instruction = PHOBE_SAFE_INSTRUCTION

    final_input_content = f"{user_input_to_use}\n\n[PHONG C√ÅCH TR·∫¢ L·ªúI HI·ªÜN T·∫†I: {instruction}]"
    contents_to_send = history + [{"role": "user", "content": final_input_content}]
    full_answer = ""

    try:
        # ‚úÖ S·ª¨ D·ª§NG client.generate_content_stream: C√°ch g·ªçi chu·∫©n cho 0.8.0
        response_stream = await asyncio.to_thread(
            lambda: client.models.generate_content_stream( # D√πng client.models cho SDK 0.8.0 (ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n)
                model=MODEL_NAME,
                contents=contents_to_send,
                temperature=0.8
            )
        )
        for chunk in response_stream:
            if chunk.text:
                text = chunk.text
                full_answer += text
                yield text
    except Exception as e:
        # N·∫øu ƒë√£ l√† 0.8.0 m√† v·∫´n l·ªói n√†y, n√≥ l√† l·ªói m√¥i tr∆∞·ªùng ho·∫∑c l·ªói logic ph·ª©c t·∫°p
        yield f"\n‚ö†Ô∏è **L·ªñI K·ª∏ THU·∫¨T NGHI√äM TR·ªåNG:** {type(e).__name__} - D√π SDK l√† 0.8.0, Python v·∫´n kh√¥ng t√¨m th·∫•y h√†m. Vui l√≤ng **Clear cache & rebuild** Render."
        return

    # L∆∞u history
    history.append({"role": "user", "content": user_input_to_use})
    history.append({"role": "model", "content": full_answer})
    session["message_count"] += 1
    save_sessions()

# ... (STATUS LOOP, SLASH COMMANDS, FLASK, BOT EVENTS, RUN gi·ªØ nguy√™n) ...

# ========== BOT EVENTS (C√ì TH√äM KI·ªÇM TRA PHI√äN B·∫¢N) ==========
@bot.event
async def on_ready():
    # Ki·ªÉm tra version SDK sau khi bot kh·ªüi ƒë·ªông
    print("‚ö° Gemini SDK version:", genai.__version__) 
    print(f"‚úÖ {BOT_NAME} ƒë√£ s·∫µn s√†ng! Logged in as {bot.user}")
    load_sessions()
    random_status.start()
    if GUILD_ID:
        await tree.sync(guild=discord.Object(GUILD_ID))
        print(f"üîÑ Slash commands ƒë√£ sync cho guild {GUILD_ID}")
    else:
        await tree.sync()
        print("üîÑ Slash commands ƒë√£ sync to√†n c·∫ßu")

# ========== RUN (Gi·ªØ nguy√™n) ==========
if __name__ == "__main__":
    keep_alive()
    bot.run(TOKEN)